{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Prediction Model\n",
    "\n",
    "The goal of this exercise is to build and evaluate your first predictive model. You will use the n-gram and backoff models you built in previous tasks to build and evaluate your predictive model. The goal is to make the model efficient and accurate.\n",
    "\n",
    "**Tasks to accomplish**\n",
    "\n",
    "- Build a predictive model based on the previous data modeling steps - you may combine the models in any way you think is appropriate.\n",
    "- Evaluate the model for efficiency and accuracy - use timing software to evaluate the computational complexity of your model. Evaluate the model accuracy using different metrics like perplexity, accuracy at the first word, second word, and third word.\n",
    "\n",
    "**Questions to consider**\n",
    "- How does the model perform for different choices of the parameters and size of the model?\n",
    "- How much does the model slow down for the performance you gain?\n",
    "- Does perplexity correlate with the other measures of accuracy?\n",
    "- Can you reduce the size of the model (number of parameters) without reducing performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.tree)\n",
    "library(DiagrammeR)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(igraph)\n",
    "library(influenceR)\n",
    "library(plyr)\n",
    "library(RColorBrewer)\n",
    "library(SnowballC)\n",
    "library(stopwords)\n",
    "library(stringi)\n",
    "library(stringr)\n",
    "library(tidyr)\n",
    "library(tidytext)\n",
    "library(tidyverse)\n",
    "library(tokenizers)\n",
    "library(tm)\n",
    "library(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path for english data\n",
    "blogs_path <- \"~/Soft/Rtest/JHU_capstone_project_data/final/en_US/en_US.blogs.txt\"\n",
    "news_path <- \"~/Soft/Rtest/JHU_capstone_project_data/final/en_US/en_US.news.txt\"\n",
    "twitter_path <- \"~/Soft/Rtest/JHU_capstone_project_data/final/en_US/en_US.twitter.txt\"\n",
    "\n",
    "# load data\n",
    "blogs <- readLines(blogs_path, encoding = \"UTF-8\", skipNul = TRUE)\n",
    "news <- readLines(news_path, encoding = \"UTF-8\", skipNul = TRUE)\n",
    "twitter <- readLines(twitter_path, encoding = \"UTF-8\", skipNul = TRUE)\n",
    "\n",
    "# Read the data files into data frames\n",
    "blogs <- data.frame(text = blogs)\n",
    "news <- data.frame(text = news)\n",
    "twitter <- data.frame(text = twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling\n",
    "set.seed(1565)\n",
    "sample_pct <- 0.1\n",
    "\n",
    "blogs_sample <- blogs %>% sample_n(., nrow(blogs)*sample_pct)\n",
    "news_sample <- news %>% sample_n(., nrow(news)*sample_pct)\n",
    "twitter_sample <- twitter %>% sample_n(., nrow(twitter)*sample_pct)\n",
    "\n",
    "# Create aggregate sample\n",
    "agg_sample <- bind_rows(\n",
    "    mutate(blogs_sample, source = 'blogs')\n",
    "    , mutate(news_sample, source = 'news')\n",
    "    , mutate(twitter_sample, source = 'twitter')\n",
    ")\n",
    "\n",
    "# change agg_sample$source type: chr --> factor\n",
    "agg_sample$source <- factor(agg_sample$source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up to save RAM Space\n",
    "rm(blogs\n",
    "   , blogs_path\n",
    "   , blogs_sample\n",
    "   , news\n",
    "   , news_path\n",
    "   , news_sample\n",
    "   , twitter\n",
    "   , twitter_path\n",
    "   , twitter_sample \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filters: non-alphanumeric's, url's, repeated letters\n",
    "replace_reg <- \"[^[:alpha:][:space:]]*\"\n",
    "replace_url <- \"http[^[:space:]]*\"\n",
    "replace_aaa <- \"\\\\b(?=\\\\w*(\\\\w)\\\\1)\\\\w+\\\\b\"  \n",
    "\n",
    "# Filter sample\n",
    "clean_sample <- agg_sample %>%\n",
    "    mutate(text = str_replace_all(text, replace_reg, \"\")) %>%\n",
    "    mutate(text = str_replace_all(text, replace_url, \"\")) %>%\n",
    "    mutate(text = str_replace_all(text, replace_aaa, \"\")) #%>%\n",
    "#    mutate(text = iconv(text, \"ASCII//TRANSLIT\")\n",
    "\n",
    "rm(\"agg_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram (2-gram)\n",
    "bigram_data <- as.data.frame(clean_sample) %>% \n",
    "    unnest_tokens(output = bigram, input = text, token = 'ngrams', n = 2)\n",
    "\n",
    "# Trigram (3-gram)\n",
    "trigram_data <- as.data.frame(clean_sample) %>%\n",
    "    unnest_tokens(output = trigram, input = text, token = 'ngrams', n = 3)\n",
    "\n",
    "# Quadgram (4-gram)\n",
    "quadgram_data <- as.data.frame(clean_sample) %>%\n",
    "    unnest_tokens(output = quadgram, input = text, token = 'ngrams', n = 4)\n",
    "\n",
    "# Quintgram (5-gram)\n",
    "quintgram_data <- as.data.frame(clean_sample) %>%\n",
    "    unnest_tokens(output = quintgram, input = text, token = 'ngrams', n = 5)\n",
    "\n",
    "# Sextgram (6-gram)\n",
    "sextgram_data <- as.data.frame(clean_sample) %>%\n",
    "    unnest_tokens(output = sextgram, input = text, token = 'ngrams', n = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce N-grams for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram (2-gram)\n",
    "bigram_cover <- bigram_data %>%\n",
    "    count(c(\"bigram\")) %>%\n",
    "    filter(freq > 10) %>%\n",
    "    arrange(desc(freq))\n",
    "\n",
    "# Trigram (3-gram)\n",
    "trigram_cover <- trigram_data %>%\n",
    "    count(c(\"trigram\")) %>%\n",
    "    filter(freq > 10) %>%\n",
    "    arrange(desc(freq))\n",
    "\n",
    "# Quadgram (4-gram)\n",
    "quadgram_cover <- quadgram_data %>%\n",
    "    count(c(\"quadgram\")) %>%\n",
    "    filter(freq > 10) %>%\n",
    "    arrange(desc(freq))\n",
    "\n",
    "# Quintgram (5-gram)\n",
    "quintgram_cover <- quintgram_data %>%\n",
    "    count(c(\"quintgram\")) %>%\n",
    "    filter(freq > 10) %>%\n",
    "    arrange(desc(freq))\n",
    "\n",
    "# sextgram (5-gram)\n",
    "sextgram_cover <- sextgram_data %>%\n",
    "    count(c(\"sextgram\")) %>%\n",
    "    filter(freq > 10) %>%\n",
    "    arrange(desc(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(list = c(\"bigram_data\", \"trigram_data\", \"quadgram_data\", \"quintgram_data\", \"sextgram_data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Distributions\n",
    "#### 3.1 Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df <- data.frame(ngram = c(rep(\"bigram\", nrow(bigram_cover))\n",
    "                               , rep(\"trigram\", nrow(trigram_cover))\n",
    "                               , rep(\"quadgram\", nrow(quadgram_cover))\n",
    "                               , rep(\"quintgram\", nrow(quintgram_cover))\n",
    "                                ,rep(\"sextgram\", nrow(sextgram_cover))\n",
    "                               )\n",
    "                     , freq = c(bigram_cover$freq\n",
    "                               , trigram_cover$freq\n",
    "                                ,quadgram_cover$freq\n",
    "                                ,quintgram_cover$freq\n",
    "                                ,sextgram_cover$freq\n",
    "                               )\n",
    "                     )\n",
    "dist_df$ngram <- as.factor(dist_df$ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim(dist_df) # 147931 x 2\n",
    "# head(dist_df, 20)\n",
    "str(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g <- NULL\n",
    "g <- ggplot(data = dist_df\n",
    "           , aes(y = freq, x = reorder(ngram, -freq)))\n",
    "g <- g + geom_boxplot()\n",
    "g <- g + scale_y_log10()\n",
    "g <- g + ggtitle(\"Distribution of N-grams\")\n",
    "g <- g + xlab(\"N-grams\") + ylab(\"Frequencies (log10)\")\n",
    "g\n",
    "ggsave(\"./data/ngrams_overview.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_word <- bigram_cover %>%\n",
    "    separate(bigram, c(\"w1\", \"w2\"), sep=\" \")\n",
    "# dim(bi_word) # 86153 x 3\n",
    "head(bi_word)\n",
    "saveRDS(bi_word, \"./data/bi_words_separated.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_cover %>%\n",
    "    top_n(20, freq) %>%\n",
    "    mutate(bigram = reorder(bigram, freq)) %>%\n",
    "    ggplot(aes(y = bigram, x = freq)) +\n",
    "    geom_col(fill = \"darkgray\") +\n",
    "    xlab(\"Frequency\") + ylab(\"Bigram\") + ggtitle(\"Top 20 Frequencies of Bigram\") #+\n",
    "#    coord_flip()\n",
    "ggsave(\"./data/ngrams_bigram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_word <- trigram_cover %>%\n",
    "    separate(trigram, c(\"w1\", \"w2\", \"w3\"), sep=\" \")\n",
    "# dim(tri_word) # 50707 x 4\n",
    "head(tri_word)\n",
    "saveRDS(tri_word, \"./data/tri_words_separated.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_cover %>%\n",
    "    top_n(20, freq) %>%\n",
    "    mutate(trigram = reorder(trigram, freq)) %>%\n",
    "    ggplot(aes(y = trigram, x = freq)) +\n",
    "    geom_col(fill = \"darkgray\") +\n",
    "    xlab(\"Frequency\") + ylab(\"Trigram\") + ggtitle(\"Top 20 Frequencies of Trigram\") #+\n",
    "#    coord_flip()\n",
    "ggsave(\"./data/ngrams_trigram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Quadgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_word <- quadgram_cover %>%\n",
    "    separate(quadgram, c(\"w1\", \"w2\", \"w3\", \"w4\"), sep=\" \")\n",
    "# dim(quad_word) # 9626 x 5\n",
    "head(quad_word)\n",
    "saveRDS(quad_word, \"./data/quad_words_separated.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadgram_cover %>%\n",
    "    top_n(20, freq) %>%\n",
    "    mutate(quadgram = reorder(quadgram, freq)) %>%\n",
    "    ggplot(aes(y = quadgram, x = freq)) +\n",
    "    geom_col(fill = \"darkgray\") +\n",
    "    xlab(\"Frequency\") + ylab(\"Quadgram\") + ggtitle(\"Top 20 Frequencies of Quadgram\") #+\n",
    "#    coord_flip()\n",
    "ggsave(\"./data/ngrams_quadgram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Quintgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quint_word <- quintgram_cover %>%\n",
    "    separate(quintgram, c(\"w1\", \"w2\", \"w3\", \"w4\", \"w5\"), sep=\" \")\n",
    "# dim(quint_word) # 1242 x 6\n",
    "head(quint_word)\n",
    "saveRDS(quint_word, \"./data/quint_words_separated.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quintgram_cover %>%\n",
    "    top_n(20, freq) %>%\n",
    "    mutate(quintgram = reorder(quintgram, freq)) %>%\n",
    "    ggplot(aes(y = quintgram, x = freq)) +\n",
    "    geom_col(fill = \"darkgray\") +\n",
    "    xlab(\"Frequency\") + ylab(\"Quintgram\") + ggtitle(\"Top 20 Frequencies of Quintgram\") #+\n",
    "#    coord_flip()\n",
    "ggsave(\"./data/ngrams_quintgram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Sextgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sext_word <- sextgram_cover %>%\n",
    "    separate(sextgram, c(\"w1\", \"w2\", \"w3\", \"w4\", \"w5\", \"w6\"), sep=\" \")\n",
    "# dim(sext_word) # 203 x 7\n",
    "head(sext_word)\n",
    "saveRDS(sext_word, \"./data/sext_words_separated.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sextgram_cover %>%\n",
    "    top_n(20, freq) %>%\n",
    "    mutate(sextgram = reorder(sextgram, freq)) %>%\n",
    "    ggplot(aes(y = sextgram, x = freq)) +\n",
    "    geom_col(fill = \"darkgray\") +\n",
    "    xlab(\"Frequency\") + ylab(\"sextgram\") + ggtitle(\"Top 20 Frequencies of Sextgram\") #+\n",
    "#    coord_flip()\n",
    "ggsave(\"./data/ngrams_sextgram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start <- Sys.time()\n",
    "bi_word <- readRDS(\"./data/bi_words_separated.RDS\")\n",
    "tri_word <- readRDS(\"./data/tri_words_separated.RDS\")\n",
    "quad_word <- readRDS(\"./data/quad_words_separated.RDS\")\n",
    "quint_word <- readRDS(\"./data/quint_words_separated.RDS\")\n",
    "sext_word <- readRDS(\"./data/sext_words_separated.RDS\")\n",
    "time_stop <- Sys.time()\n",
    "duration <- time_stop - time_start\n",
    "duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Prediction Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.tree)\n",
    "library(DiagrammeR)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(igraph)\n",
    "library(influenceR)\n",
    "library(plyr)\n",
    "library(RColorBrewer)\n",
    "library(SnowballC)\n",
    "library(stopwords)\n",
    "library(stringi)\n",
    "library(stringr)\n",
    "library(tidyr)\n",
    "library(tidytext)\n",
    "library(tidyverse)\n",
    "library(tokenizers)\n",
    "library(tm)\n",
    "library(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start <- Sys.time()\n",
    "bi_word <- readRDS(\"./data/bi_words_separated.RDS\")\n",
    "tri_word <- readRDS(\"./data/tri_words_separated.RDS\")\n",
    "quad_word <- readRDS(\"./data/quad_words_separated.RDS\")\n",
    "quint_word <- readRDS(\"./data/quint_words_separated.RDS\")\n",
    "sext_word <- readRDS(\"./data/sext_words_separated.RDS\")\n",
    "time_stop <- Sys.time()\n",
    "duration <- time_stop - time_start\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(bi_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Matching functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram prediction function\n",
    "bigram <- function(inputWord){\n",
    "    num <- length(inputWord)\n",
    "    filter(bi_word, w1 == inputWord[num]) %>%\n",
    "    top_n (1, freq) %>%\n",
    "    filter(row_number() == 1L) %>%\n",
    "    select(num_range(\"w\", 2)) %>%\n",
    "    as.character() -> out\n",
    "    ifelse(out == \"character(0)\", \"?\", return(out))\n",
    "}\n",
    "\n",
    "# Trigram prediction function\n",
    "trigram <- function(inputWord)\n",
    "    {\n",
    "    num <- length(inputWord)\n",
    "    filter(tri_word, \n",
    "           w1 == inputWord[num-1]\n",
    "          ,w2 == inputWord[num]) %>%\n",
    "    top_n (1, freq) %>%\n",
    "    filter(row_number() == 1L) %>%\n",
    "    select(num_range(\"w\", 3)) %>%\n",
    "    as.character() -> out\n",
    "    ifelse(out == \"character(0)\", \"?\", return(out))\n",
    "}\n",
    "\n",
    "# Quadgram prediction function\n",
    "quadgram <- function(inputWord)\n",
    "    {\n",
    "    num <- length(inputWord)\n",
    "    filter(quad_word, \n",
    "           w1 == inputWord[num-2]\n",
    "          ,w2 == inputWord[num-1]\n",
    "          ,w3 == inputWord[num]) %>%\n",
    "    top_n (1, freq) %>%\n",
    "    filter(row_number() == 1L) %>%\n",
    "    select(num_range(\"w\", 4)) %>%\n",
    "    as.character() -> out\n",
    "    ifelse(out == \"character(0)\", \"?\", return(out))\n",
    "}\n",
    "\n",
    "# Quintgram prediction function\n",
    "quintgram <- function(inputWord)\n",
    "    {\n",
    "    num <- length(inputWord)\n",
    "    filter(quint_word, \n",
    "           w1 == inputWord[num-3]\n",
    "          ,w2 == inputWord[num-2]\n",
    "          ,w3 == inputWord[num-1]\n",
    "          ,w4 == inputWord[num]) %>%\n",
    "    top_n (1, freq) %>%\n",
    "    filter(row_number() == 1L) %>%\n",
    "    select(num_range(\"w\", 5)) %>%\n",
    "    as.character() -> out\n",
    "    ifelse(out == \"character(0)\", \"?\", return(out))\n",
    "}\n",
    "\n",
    "# Sextgram prediction function\n",
    "sextgram <- function(inputWord)\n",
    "    {\n",
    "    num <- length(inputWord)\n",
    "    filter(sext_word, \n",
    "           w1 == inputWord[num-4]\n",
    "          ,w2 == inputWord[num-3]\n",
    "          ,w3 == inputWord[num-2]\n",
    "          ,w4 == inputWord[num-1]\n",
    "          ,w5 == inputWord[num]) %>%\n",
    "    top_n (1, freq) %>%\n",
    "    filter(row_number() == 1L) %>%\n",
    "    select(num_range(\"w\", 6)) %>%\n",
    "    as.character() -> out\n",
    "    ifelse(out == \"character(0)\", \"?\", return(out))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictNgrams <- function(input){\n",
    "    # create dataframe\n",
    "    input <- data_frame(text = input)\n",
    "    # clean the input text\n",
    "    replace_reg <- \"[^[:alpha:][:space:]]*\"\n",
    "    input <- input %>%\n",
    "        mutate(text = str_replace_all(text, replace_reg, \"\"))\n",
    "    # find word count, separate words, lower case\n",
    "    input_count <- str_count(input, boundary(\"word\"))\n",
    "    input_words <- tolower(unlist(str_split(input, boundary(\"word\"))))\n",
    "    # call the matching functions\n",
    "    out <- if (input_count == 1) {bigram(input_words)}\n",
    "            else if (input_count == 2) {trigram(input_words)}\n",
    "            else if (input_count == 3) {quadgram(input_words)}\n",
    "            else if (input_count == 4) {quintgram(input_words)}\n",
    "            else if (input_count == 5) {sextgram(input_words)}\n",
    "    return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictNgrams(\"case of\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
